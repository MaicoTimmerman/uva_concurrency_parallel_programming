\documentclass[a4paper,12px]{article}

\usepackage{graphicx}
\usepackage[english]{babel}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{xifthen}
\usepackage[linesnumberedhidden, titlenotnumbered]{algorithm2e}
\usepackage{lipsum}
\usepackage{hyperref}
\usepackage{array}
\usepackage{tabularx}

\usepackage{minted}
\usepackage{caption}
\usepackage{amssymb}
\usepackage{natbib}

\pagestyle{fancy}
\lhead{\includegraphics[width=7cm]{logoUvA}}
\rhead{\footnotesize \textsc {Paper\\ \titel}}
\lfoot
{
    \footnotesize \studentA
    \ifthenelse{\isundefined{\studentB}}{}{\\ \studentB}
    \ifthenelse{\isundefined{\studentC}}{}{\\ \studentC}
    \ifthenelse{\isundefined{\studentD}}{}{\\ \studentD}
    \ifthenelse{\isundefined{\studentE}}{}{\\ \studentE}
}
\cfoot{}
\rfoot{\small \textsc {Page \thepage\ of \pageref{LastPage}}}
\renewcommand{\footrulewidth}{0.5pt}

\fancypagestyle{firststyle}
{
    \vspace*{6cm}
    \fancyhf{}
    \renewcommand{\headrulewidth}{0pt}
    \chead{\includegraphics[width=7cm]{logoUvA}}
    %\rfoot{\small \textsc {Page \thepage\ of \pageref{LastPage}}}
}

\setlength{\topmargin}{-0.3in}
\setlength{\textheight}{630pt}
\setlength{\headsep}{40pt}

% =================================== DOC INFO ===================================

\newcommand{\titel}{Trade-offs in distributed file systems}
\newcommand{\opdracht}{Examples and applications}
\newcommand{\docent}{Ana Varbanescu}
\newcommand{\cursus}{Concurrency and Parallel Programming}
\newcommand{\vakcode}{5062COPP6Y}
\newcommand{\datum}{\today}
\newcommand{\studentA}{Robin Klusman}
\newcommand{\uvanetidA}{10675671}
\newcommand{\studentB}{Maico Timmerman}
\newcommand{\uvanetidB}{10542590}
%\newcommand{\studentC}{Boudewijn Braams}
\newcommand{\uvanetidC}{10401040}
%\newcommand{\studentD}{Govert Verkes}
\newcommand{\uvanetidD}{10211748}
%\newcommand{\studentE}{Naam student 5}
\newcommand{\uvanetidE}{UvAnetID student 5}

% ===================================  ===================================

\begin{document}
\thispagestyle{firststyle}
\begin{center}
    \rule{\linewidth}{0.5pt} \\[0.4cm]
    {\LARGE \bfseries \titel}
    \rule{\linewidth}{0.5pt} \\[0.2cm]
    \textsc{\Large \opdracht}\\[0.2cm]
    \vspace{0.2cm}
    {\large \datum  \\[0.4cm]}

    \begin{minipage}{0.4\textwidth}
        \begin{flushleft}
            \emph{Authors:}\\
            {\studentA \\ {\small \uvanetidA \\[0.2cm]}}
            \ifthenelse{\isundefined{\studentB}}{}{\studentB \\ {\small \uvanetidB \\[0.2cm]}}
            \ifthenelse{\isundefined{\studentC}}{}{\studentC \\ {\small \uvanetidC \\[0.2cm]}}
            \ifthenelse{\isundefined{\studentD}}{}{\studentD \\ {\small \uvanetidD \\[0.2cm]}}
            \ifthenelse{\isundefined{\studentE}}{}{\studentE \\ {\small \uvanetidE \\ [0.2cm]}}
        \end{flushleft}
    \end{minipage}
    ~
    \begin{minipage}{0.4\textwidth}
        \begin{flushright}
            \emph{Supervisor:} \\
            \docent \\[0.2cm]
            \emph{Course:} \\
            \cursus \\[0.2cm]
            \emph{Course code:} \\
            \vakcode \\[0.2cm]
        \end{flushright}
    \end{minipage}\\[1 cm]
\end{center}


% =================================== FRONT PAGE ===================================

\clearpage
\vspace*{0.5cm}
\tableofcontents
\clearpage



% =================================== MAIN TEXT ===================================

\section{Abstract}

A distributed file system is a client and server system where clients can access
data located on the servers. The servers can be spread over multiple locations
and should still provide reliable access to files. To do so there are a few
requirements that need to be met: universality, performance, and fault
tolerance.  In this paper our aim is to examine what trade-offs designers of
distributed file systems made in order to make their file systems work. To do
this we will discuss three example distributed file systems, LOCUS, Andrew and
Ceph and look at how they met these requirements or whether they needed to
compromise in some way. We will also compare the three to see how distributed
file systems developed over the years.

\section{Introduction}

A file system is the part of a computer system that manages long term storage of
data. The most common file system is a centralized file system. This type of
file system is the one we usually find in a personal computer, here files are
stored on a single storage device at a single location.

Another type of file system is the distributed file system, in these file
systems data can be stored on multiple storage devices that also do not
necessarily need to be at the same location. These file systems are useful when
multiple people need to share their data quickly and securely.

In this paper our aim is to find out what trade-offs were made exactly in the
making of different distributed file systems. In addition we will look at how
distributed file systems have developed over the years. We will do this by
looking at three examples and comparing the properties of those to each other.

In the next section we take a closer look at what a distributed file system is,
and why it is useful. Then we will discuss in short what the requirements are
for a distributed file system to be effective and useful. In the section
thereafter we will look at a couple of examples of distributed file systems to
see what trade-offs they have had to make. Then the most important trade-offs
will be summarized and discussed in the last section of this paper.

\section{The Distributed File System}

In this section we take a more in depth look at what a distributed file system
exactly is, and why it is useful. A distributed file system is a system of
servers and clients (in some cases devices can be both server and client at the
same time) where data is spread over multiple storage devices (servers) but can
be accessed by clients as though it were on their own device. \citep{concepts}

A distributed file system is particularly convenient in large corporations where
employees each have their own account that they can use to log in to any
computer at the office. The employees will want to access their files regardless
of which computer they are logged in from. A distributed file system can make
sure every employee will have access to their files as though the files were on
the computer currently being used.

\section{Requirements}

Here we will discuss in short what the requirements are of a distributed file
system in order for it to be effective. First of all a user must be able to
access the files they are trying to access in a way that is (preferably) no
different accessing files on a centralized file system. And a user must also be
able to access their files located on the distributed file system from any
machine within the system. \citep{concepts} Another very important requirement is
of course the performance of the system. If a file system is too slow, it
becomes impractical to use since every time a client requests access to a file
they would have to wait for it. Another key concern is the system's fault
tolerance. Being fault tolerant means that the system will not completely crash
or shut down when a fault occurs, instead it should either manage the fault or
continue functioning with reduced functionality until the fault is
solved. \citep{concepts}

\section{LOCUS}

The LOCUS distributed file system was developed in the early 1980s. LOCUS is a
system that stands out due to it's features. These features include automatic
management of replicated data, atomic file updates and more. \citep{concepts}

LOCUS uses file-groups to create containers of storage sites. These file-groups
can exist of multiple physical containers. LOCUS keeps track of files using
i-nodes, just as UNIX file-systems do. LOCUS keeps a list of file designators,
these designators are a combination of logical file-groups and the i-nodes of
files. \citep{concepts} By keeping these desiccators centralized, easy access to
the file system is guaranteed.

Fault tolerance is handled within LOCUS by keeping a policy of consistency among
copies of a file. The policy is to allow update only in a partition that has the
primary copy of the file. From there file is updated to its secondary copies
after a commit has been done on the primary copy.

The biggest trade-off within the LOCUS file system is that it does not perform
well when scaled. The scalability of the system is limited because all
file-groups have a single synchronization site. \citep{concepts} This site keeps
track of all files that are in the file-group. Heavily accessed file-groups cannot
keep up with the number of requests, if the norm gets bigger. If however the I/O
operations are spread over the file-groups, the LOCUS file system can be fast,
because locking of files is not required system-wide, only in the filegroup the
file is in.

\section{Andrew}

The distributed file system used by the Andrew distributed computing environment
(hereafter referred to as simply Andrew) started development in 1983, just after
the LOCUS file system was developed. In creating Andrew the designers main goals
were performance and scalability. This means that Andrew had to provide a
relatively good performance and also make sure the performance does not suffer
too much when scaling up the system.\citep{andrew}

Andrew works by using dedicated servers and clients. The clients each have local
storage and are also able to access the shared storage located on the servers.
The Servers are collectively responsible for managing the shared
storage. \citep{concepts} When a client wants to retrieve a file from the shared
storage it will send a request to a server. Servers continuously listen for
client connections and as soon as a client wants to connect the server creates a
new process to handle the communication with that client. The process is only
terminated when the client disconnects. \citep{andrew} Servers contain both data
and links to data that exists on other servers.

In Andrew universality is achieved through caching. When a file is requested it
is put into local storage before the user can manipulate the file. This means
that the way a user interacts with file is much the same as on a centralised
file system, since the file is actually copied to local memory. The only
difference is the time it takes to load a not yet cached file. \citep{concepts}

Caching also plays a great part in performance. Because files are cached
locally, data transfers between clients and servers occur less frequently. Since
data transfers to servers are very slow and local storage accesses are
relatively fast this significantly increases performance. In addition, the
performance when scaling the system is also very good since the clients can
execute programs that are stored locally without any server interaction, thus
not overloading the server with requests. \citep{andrew}

A major trade-off that was made in Andrew is the fact that they sacrifice fault
tolerance for performance. Due to the way the caching works it is rather
difficult to recover data. Data is only synchronised with the server on a file
open or close. \citep{andrew} So in case of a crash, any unsynchronised data will
be lost.  Of course this increases performance because less communication is
needed, but it does make the system less tolerant of faults.

\section{Ceph}

The Ceph distributed file system was initially developed late 2007 by Sage Weil
during his doctoral dissertation. \citep{weil2006ceph} Ceph's main goals are to
be completely distributed without a single point of failure, scalable to the
exabyte level and freely-available. The data is replicated, making it highly
fault tolerant.

Ceph is a implementation of a distributed file system that eliminates allocation
lists entirely. Instead, file data is divided into objects, while a data
distribution function called CRUSH assigns objects to storage devices. This way
look-ups are unnecessary, because any user can simply calculate the name and the
location of a set of objects forming a file.  Using this procedure, meta data
operations like \textit{open}, or \textit{rename}, do not need access to the
data on the servers, but can be handled by a dedicated meta-data server.
\citep{weil2006ceph}

Metadata operations can take up to half of the operations of the distributed
file system. Therefor Ceph has an aggressive prefetching algorithm to have
metadata in the system before it is requested.  Furthermore Ceph uses its
knowledge of metadata popularity to provide a wide distribution for hot spots
only when needed and without incurring the associated overhead and loss of
directory locality in the general case.

Ceph implements fault tolerance, by replicating all data it has. Data is
replicated in terms of placement groups, each of which is mapped to an ordered
list of $n$ object storage devices (for $n$-way replication).
\citep{weil2006ceph} Disadvantage of this system is that writes are slow, due to
having to having to update all replicates in the system. However, this reliefs
the head node of doing writes to all replicates.

The major trade-off with Ceph is the speed of write operations. If Ceph is used
in a read intensive, this does not create a bottleneck. However in write
intensive environments this can create performance issues. All clients have to
wait for a write to complete to all replicates.

\section{Discussion}
As can be seen in the above sections, each implementation of a distributed file
system focusses on different aspects. Starting with the earliest of our three
examples, LOCUS, we see that they chose to implement better fault tolerance over
performance when scaled. This means that LOCUS operates well when the system is
not too large, but it cannot compare to other distributed file systems when used
with a larger system.

In Andrew we see exactly the opposite, here fault are tolerated less in favour
of better performance and scalability. In case of a fault Andrew is likely to
lose data that was not yet saved to the server. But when everything is working
well, Andrew is much faster and much more scalable that LOCUS.

In Ceph the designers once again wanted make their system highly fault tolerant.
They made sure data is not easily lost in case of a fault and to do this they
only sacrificed a little performance, namely the write speed. Scalability and
read performance are however largely unaffected by this change.

We can see that on the subject of trade-offs, distributed file systems have
minor changes have occured. Choices always have to be made to emphasize one
aspect over the other. We do see that in the most recent system, Ceph, a
significantly better trade-off is made compared to the same type of trade-off
made in LOCUS over 20 years prior.



% =================================== REFERENCES ===================================

\clearpage
\bibliographystyle{apalike}
\bibliography{bib}

\end{document}
